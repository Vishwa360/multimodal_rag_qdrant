# Multimodal RAG with Qdrant & CLIP

This project implements a **Multimodal Retrieval-Augmented Generation (RAG)** system using **Qdrant** as the vector database, **CLIP** for embeddings, and **GPT-4o** for generation.

It allows you to:
1.  **Index Images**: Convert images into vector embeddings.
2.  **Multimodal Search**: Search for images using text queries (e.g., "motivational quote").
3.  **Generative QA**: Ask questions about the retrieved images, and get answers generated by GPT-4o.

## Features

-   **Hybrid Search**: Retrieve images using natural language text queries.
-   **Vision-Language Generation**: Uses GPT-4o to analyze retrieved images and answer user questions.
-   **Automated Format Handling**: Automatically converts unsupported image formats (like AVIF/WEBP) to JPEG on-the-fly for GPT-4o compatibility.
-   **Flexible Deployment**: Supports both in-memory Qdrant (for testing) and persistent Docker-based Qdrant instances.

## Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/Vishwa360/multimodal_rag_qdrant.git
    cd multimodal_rag_qdrant
    ```

2.  **Install dependencies:**
    ```bash
    pip install qdrant-client sentence-transformers pillow torch openai python-dotenv
    ```

3.  **Set up Environment Variables:**
    Create a `.env` file in the root directory and add your OpenAI API key:
    ```env
    OPENAI_API_KEY=sk-your-api-key-here
    ```

## Usage

1.  **Prepare Data:**
    Place your images in the `data/images` directory. Supported formats: JPG, PNG, WEBP, AVIF, BMP.

2.  **Run the Test Script:**
    The `test_multimodal.py` script performs an end-to-end test: finds images, indexes them, retrieves relevant matches for a query, and generates an answer.
    ```bash
    python test_multimodal.py
    ```

### Using Qdrant with Docker (Optional)

For persistent storage, run Qdrant using Docker:
```bash
docker run -p 6333:6333 -v $(pwd)/qdrant_db:/qdrant/storage qdrant/qdrant
```
The script will automatically detect the Docker instance at `http://localhost:6333`. If not found, it falls back to in-memory mode.

## Project Structure

-   `multimodal_rag.py`: Core class handling Qdrant interaction, CLIP embedding, and GPT-4o generation.
-   `test_multimodal.py`: Demonstration script for the entire pipeline.
-   `agent.py`: (Legacy) Initial LangGraph experiment.
-   `data/`: Directory for storing input images.

## License
MIT
